{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro 2 - Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort changes the list\n",
    "t = ['d', 'c', 'e', 'b', 'a']\n",
    "t.sort()\n",
    "t.sort(reverse=True)\n",
    "\n",
    "# Sorted does not\n",
    "t = ['d', 'c', 'e', 'b', 'a']\n",
    "print 'Sorted version of t =', sorted(t)\n",
    "\n",
    "# Appending elements\n",
    "t.append('a')\n",
    "\n",
    "# Deleting elements\n",
    "item = t.pop()\n",
    "print 'Deleted item', item, 'from end of the list'\n",
    "\n",
    "# enumerate() gives the list index and list item together\n",
    "for index, item in enumerate(t):\n",
    "    print 'Item number ', index, 'is ', item\n",
    "    \n",
    "# Create a tuple\n",
    "x = ('John', 'Doe', 123)\n",
    "print x\n",
    "\n",
    "# Tuple assignment\n",
    "firstname, lastname, employee_id = x\n",
    "print 'Welcome ', firstname, lastname, '!'\n",
    "\n",
    "# Dictionary\n",
    "eng2sp = {} # empty dictionary\n",
    "eng2sp['one'] = 'uno'\n",
    "eng2sp['two'] = 'dos'\n",
    "print eng2sp\n",
    "print eng2sp.keys()  # Returns a list of keys\n",
    "print eng2sp.values() # Returns the list of values\n",
    "print eng2sp.items() # Returns all (key, value) pairs as a list of tuples.\n",
    "\n",
    "# SECOND WAY: Iterate over key-value pairs\n",
    "eng2sp_cap = {}\n",
    "for key, value in eng2sp.items(): # this iterates over (key, value) tuples\n",
    "    capitalized_value = value.upper()\n",
    "    eng2sp_cap[key] = capitalized_value\n",
    "print 'Capitalized dictionary:', eng2sp_cap\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro 4 - String Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating over string\n",
    "for char in fruit:\n",
    "    print char\n",
    "    \n",
    "# Convert string into list and back\n",
    "orig_list = list(orig_string)  # this converts the string into a list\n",
    "blanked_out_string = ''.join(orig_list) # Convert list back into string\n",
    "\n",
    "We used the join method, which concatenates a list of items using a delimiter.\n",
    "\n",
    "delimiter_string.join([item1, item2, item3, ...])\n",
    "Here, we called join on the empty string '' since we did not want any extra stuff between the character list.\n",
    "\n",
    "# Strip characters from string\n",
    "'AAA Car Insurance'.lstrip('A')\n",
    "'AAA Car Insurance'.rstrip('E')\n",
    "\n",
    "# Break up string into list based on an assigned delimiter\n",
    "\"A told B, and B told C, I'll race you to the top, of the coconut tree\".split(', ')\n",
    "\"A told B, and B told C, I'll race you to the top, of the coconut tree\".split(' ')\n",
    "\n",
    "s = \"{12.4, 3.6}\" #how do I get a list of these numbers?\n",
    "\n",
    "s = [float(i) for i in s.lstrip('{').rstrip('}').split(',')]\n",
    "\n",
    "# Reading in lines from a file\n",
    "for line in fp:  # <--- Iterate over lines from a file\n",
    "    line = line.rstrip()\n",
    "    part_name, num_units, price_per_unit, total_price_of_part = line.split(',')\n",
    "    price_of_car += int(total_price_of_part)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Expressions\n",
    "\n",
    "Let's look a bit more at some commonly used patterns.\n",
    "\n",
    "        \n",
    "[...] means match any character within the square brackets ([abcd] means match any one of 'a' 'b' 'c' 'd')\n",
    "\n",
    "[^...] means match anything except the characters within the brackets\n",
    "\n",
    "[a-zA-Z]; [0-9]\n",
    "\n",
    ".(the \"full stop\" sign) means match any one character, whatever it is (this is called a wild card) \n",
    "\n",
    "\\. means match the full-stop character\n",
    "\n",
    "There are several useful shorthands as well:\n",
    "\n",
    "* **\\\\w** is shorthand for [a-zA-Z0-9\\_]\n",
    "* **\\\\d** is shorthand for [0-9]\n",
    "* **\\\\s** is shorthand for a space or a tab, often used as delimiter\n",
    "\n",
    "Pattern Repetitions\n",
    "* **\\\\w** matches one English character\n",
    "* **\\\\w?** matches at most one English character (e.g., 'https?' matches both 'http' and 'https')\n",
    "* **\\\\w\\*** matches zero or more English characters (e.g., both '' and 'Henry')\n",
    "* **\\\\w+** matches one or more English characters (e.g., 'Henry', but not '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find strings that contain numbers\n",
    "for one_string in string_list:\n",
    "    matches = re.findall('[0-9]', one_string)\n",
    "    if len(matches) > 0:\n",
    "        print 'The matches in \"'+ one_string + '\" are:', matches\n",
    "    else:\n",
    "        print 'No matches in \"' + one_string + '\"'\n",
    "\n",
    "# Find phone numbers\n",
    "def find_phone_number(s):\n",
    "    \"\"\"Given a string, find a phone number in it.\n",
    "       Consider only two forms:\n",
    "       123.456.7890 or\n",
    "       123-456-7890\"\"\"\n",
    "    print re.findall('\\s(\\d\\d\\d[\\.-]\\d\\d\\d[\\.-]\\d\\d\\d\\d)\\s', s) \n",
    "    #\\space\\digit\\digit\\digit[full-stop or hyphen]\\digit\\digit\\digit[full-stop or hyphen]\\digit\\digit\\digit\\digit\\space\n",
    "    #add parentheses to select what of the match you want to keep (i.e. - here it excludes the spaces in the result)\n",
    "    \n",
    "find_phone_number(' Call me at 512-232-1234 or 888.291.2135 ASAP')\n",
    "\n",
    "\n",
    "# Find twitter handles\n",
    "def find_twitter_handles_2(s):\n",
    "    print re.findall('\\s@[a-zA-Z0-9_]+', s)\n",
    "\n",
    "blatantly_false_string = \"\"\"\n",
    "I'm gonna have the MOST followers! More tha @BarackObama, bigger\n",
    "that @katyperry, gonna top @taylorswift13, snuff out @Harry_Styles,\n",
    "and all you punks out there! That's right, contact me at \n",
    "bigdaddy@utexas.edu while I set up my account.\n",
    "\"\"\"\n",
    "\n",
    "find_twitter_handles_2(blatantly_false_string)\n",
    "\n",
    "# Find email addresses (the email address must contain only [a-z] or [A-Z] or '.', and it must start and end with [a-z] or [A-Z].)\n",
    "def find_emails_2(s):\n",
    "    print re.findall('[a-zA-Z][a-zA-Z\\.]*@[a-zA-Z\\.]*[a-zA-Z]', s)\n",
    "    \n",
    "find_emails_2('Hello from csev@umich.edu to cwen@iupui.edu about the meeting @2PM')\n",
    "find_emails_2(header_string)\n",
    "\n",
    "# Find webpage, we can put parentheses around the part we want as the result.\n",
    "def find_URLs_2(s):\n",
    "        print re.findall('<a href=\"(https?://[^\"]+)\">', s)\n",
    "\n",
    "find_URLs_2(test_string_1)\n",
    "find_URLs_2(test_string_2)\n",
    "\n",
    "# Check if a complaint type contains the word 'Noise'\n",
    "def noisy(s):\n",
    "    \"\"\"Given a Complaint Type string, return True if it is\n",
    "       a noise-related complaint.\"\"\"\n",
    "    return (len(re.findall('Noise', s)) > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas 1 - Series and DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Mean =', unit_price_series.mean()  # Average unit price\n",
    "print 'Variance =', unit_price_series.var() # Variance of unit prices\n",
    "print 'Max =', unit_price_series.max(), ' for car part =', unit_price_series.idxmax()\n",
    "\n",
    "# Find missing elements\n",
    "mask = missing_series.isnull()\n",
    "mask\n",
    "\n",
    "# Drop missing elements\n",
    "missing_series.dropna()\n",
    "\n",
    "# Fill missing values\n",
    "missing_series.fillna(-1)\n",
    "missing_series.fillna(missing_series.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing rows of a dataframe, get all information about Windows\n",
    "car_table.loc['Windows']\n",
    "\n",
    "# Get two rows\n",
    "car_table.loc[['Engine', 'Body']]\n",
    "\n",
    "# Get total unit price (one column) of just Wheels and Doors\n",
    "car_table.loc[['Wheels', 'Doors'], ['Total unit price']]\n",
    "\n",
    "# First two rows and columns\n",
    "car_table.iloc[:2, :2]\n",
    "\n",
    "# To flip the index and columns\n",
    "car_table.T   # T is short-form for \"transpose\", which flips rows and columns of a matrix\n",
    "\n",
    "# Read in dataframe\n",
    "df = pd.read_csv('Intro_4_Data/CarParts.csv')\n",
    "df\n",
    "\n",
    "# Set index\n",
    "df = df.set_index('Part name', inplace=True)\n",
    "df\n",
    "\n",
    "# Reset index\n",
    "df = df.reset_index() #resets index\n",
    "df\n",
    "\n",
    "# Operations on dataframe\n",
    "df['Price per unit'].mean()\n",
    "\n",
    "# \"Apply\" a range function to each column of the DataFrame\n",
    "def get_column_range(x):\n",
    "    # x here is a Series\n",
    "    return x.max() - x.min()\n",
    "\n",
    "df.apply(get_column_range)\n",
    "\n",
    "# Sort the DataFrame by its index.\n",
    "df.sort_index()\n",
    "\n",
    "# Sort the DataFrame by price per unit\n",
    "df.sort_values(by='Price per unit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas 2 - Complaints Data Analysis Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram of the top-20 complaints.\n",
    "top_20_vc = vc[:20]\n",
    "top_20_vc.plot(kind='bar')\n",
    "\n",
    "# Plot a histogram of the top-20 complaints normalized by total number of complaints\n",
    "top_20_vc_fraction = top_20_vc / vc.sum() #create new series - each top_20_vc row divided by total number of complaints\n",
    "top_20_vc_fraction.plot(kind='bar')\n",
    "\n",
    "# Remove 'unspecified' values\n",
    "mask = (orig_data['Borough'] == 'Unspecified')\n",
    "orig_data.loc[mask, 'Borough'] = np.nan #This sets the value to NaN\n",
    "\n",
    "# Detect missing boroughs by creating two masks\n",
    "mask_borough = borough_zip['Borough'].notnull()\n",
    "mask_zip = borough_zip['Incident Zip'].notnull()\n",
    "mask = (mask_borough & mask_zip)  # mask is True only if both mask_borough and mask_zip are True\n",
    "borough_zip_clean = borough_zip[mask]\n",
    "\n",
    "# Remove missing boroughs by using dropna\n",
    "borough_zip_clean = borough_zip.dropna(how='any')\n",
    "\n",
    "# Drop duplicates, subset can be removed to drop duplicates across entire df, or include multiple columns\n",
    "borough_zip_dedup = borough_zip_clean.drop_duplicates(subset='Incident Zip')\n",
    "\n",
    "# The following is what we did over several slides, all consolidated into 1 line\n",
    "zip_per_borough = orig_data[['Borough', 'Incident Zip']].dropna(how='any') \\\n",
    "                                                        .drop_duplicates() \\\n",
    "                                                        ['Borough'] \\\n",
    "                                                        .value_counts()\n",
    "\n",
    "# use .map to iterate over the 'Complaint Type' series, create a mask for every time 'Noise' apppears in complaint\n",
    "# See last example in RE section\n",
    "noise_mask = orig_data['Complaint Type'].map(noisy) \n",
    "noise_complaints = orig_data[noise_mask]\n",
    "\n",
    "# Create a new column by combining values by two other columns\n",
    "noise_complaints_copy = noise_complaints.copy()\n",
    "noise_complaints_copy['Street & Borough'] = noise_complaints['Street Name'] + \\\n",
    "                                            ' (' + noise_complaints['Borough'] + ')'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas 3 - Merging and Reshaping\n",
    "\n",
    "Apart from pivot_table(), there are two main ways to reshape the data:\n",
    "\n",
    "* **stack**, which \"rotates\" or pivots from columns to index, and\n",
    "* **unstack**, which does the opposite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dataframes\n",
    "questions_askers = df1.merge(df2,\n",
    "                                   left_on='OwnerUserId',\n",
    "                                   right_on='Id',\n",
    "                                   suffixes=['_df1', '_df2'])\n",
    "\n",
    "# Pivot Table \n",
    "# How many complaints of each type occur in each borough?\n",
    "pivoted = pd.pivot_table(complaints,\n",
    "                         index='Complaint Type',\n",
    "                         columns='Borough',\n",
    "                         values='count',\n",
    "                         aggfunc=sum) # aggfunc=sum says take the total number of noise complaints.\n",
    "\n",
    "# More complicated pivot table\n",
    "pivot_all = pd.pivot_table(complaints,\n",
    "                           index=['Complaint Type', 'Borough'],\n",
    "                           columns=['Agency', 'Status'],\n",
    "                           values='count',\n",
    "                           fill_value=0)  # fill in missing values\n",
    "\n",
    "# idxmax to find max index for each column\n",
    "complaint_agency.idxmax()\n",
    "complaint_agency.T.idxmax() #to get max column for each index\n",
    "\n",
    "# rank users via rank()\n",
    "reputation_rank = askers['Reputation'].rank(ascending=False)\n",
    "\n",
    "# Get percentiles via qcut\n",
    "reputation_percentile = pd.qcut(reputation_rank,\n",
    "                                10,\n",
    "                                labels=['0-10', '10-20', '20-30',\n",
    "                                        '30-40', '40-50', '50-60',\n",
    "                                        '60-70', '70-80', '80-90', '90-100'])\n",
    "\n",
    "# Add this as a new column to askers\n",
    "askers['Reputation Percentile'] = reputation_percentile\n",
    "\n",
    "# Stack\n",
    "stacked = pivoted.stack()\n",
    "# Unstack\n",
    "stacked.unstack('Borough')\n",
    "\n",
    "# Getting the max value or index for a Series is easy.\n",
    "print 'Most prevalent complaint for BRONX is', pivoted['BRONX'].idxmax() # Gets max index name\n",
    "print 'which occurred', pivoted['BRONX'].max(), 'times.' #Gets max value\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas 4 - Visualization\n",
    "\n",
    "When we do\n",
    "\n",
    "    Series.plot(kind='bar')\n",
    "\n",
    "it plots a normal bar plot. Instead, when we do\n",
    "\n",
    "    DataFrame.plot(kind='bar')\n",
    "\n",
    "it plots each column (i.e., each Series) in the bar plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots\n",
    "plot(cars['wt'], cars['mpg'], marker='o', color='blue', linestyle='None')\n",
    "xlabel('Weight')\n",
    "ylabel('Miles per Gallon')\n",
    "title('Weight versus Efficiency')\n",
    "show()\n",
    "\n",
    "# Scatter plot - 3 groups on same plot\n",
    "plot(c4['wt'], c4['mpg'], marker='o', linestyle='None', label='4 cylinder')\n",
    "plot(c6['wt'], c6['mpg'], marker='o', linestyle='None', label='6 cylinder')\n",
    "plot(c8['wt'], c8['mpg'], marker='o', linestyle='None', label='8 cylinder')\n",
    "xlabel('Weight')\n",
    "ylabel('Miles per Gallon')\n",
    "legend(numpoints=1, loc='best')\n",
    "show()\n",
    "\n",
    "# Scatter plot - 3 groups on different plots\n",
    "# First, create a blank figure and \"axis\" objects\n",
    "fig, (ax1, ax2, ax3) = subplots(nrows=3,\n",
    "                                ncols=1,\n",
    "                                sharex=True,\n",
    "                                sharey=True,\n",
    "                                figsize=(8, 12))\n",
    "\n",
    "# Each \"axis\" object corresponds to one subplot\n",
    "# Fill in the subplots.\n",
    "ax1.plot(c4['wt'], c4['mpg'], marker='o', color='blue', linestyle='None')\n",
    "ax1.set_title('4 cylinder')\n",
    "ax1.set_ylabel('MPG')\n",
    "\n",
    "ax2.plot(c6['wt'], c6['mpg'], marker='o', color='green', linestyle='None')\n",
    "ax2.set_title('6 cylinder')\n",
    "ax2.set_ylabel('MPG')\n",
    "\n",
    "ax3.plot(c8['wt'], c8['mpg'], marker='o', color='red', linestyle='None')\n",
    "ax3.set_title('8 cylinder')\n",
    "ax3.set_ylabel('MPG')\n",
    "ax3.set_xlabel('Weight')\n",
    "\n",
    "show()\n",
    "\n",
    "# Line graphs\n",
    "plot(births['year'], births['M'], marker='None', linestyle='-', label='boys')\n",
    "plot(births['year'], births['F'], marker='None', linestyle='-', label='girls')\n",
    "xlabel('Year')\n",
    "ylabel('Number of births')\n",
    "legend(loc='best')\n",
    "show()\n",
    "\n",
    "# Fit a regression line to a graph\n",
    "# Regress the mpg values against the weight values\n",
    "# We will see this in much more detail in a later lecture\n",
    "import statsmodels.api as sm\n",
    "from patsy import dmatrices\n",
    "y, X = dmatrices('mpg ~ wt', cars, return_type='dataframe')\n",
    "result = sm.OLS(y, X).fit()\n",
    "\n",
    "slope = result.params['wt']\n",
    "intercept = result.params['Intercept']\n",
    "print 'mpg = {:.4f} + {:.4f} * wt'.format(intercept, slope)\n",
    "\n",
    "predicted = cars['wt'] * slope + intercept\n",
    "regression_predictions = Series(predicted.values,\n",
    "                                index=cars['wt'])\n",
    "regression_predictions[:5]\n",
    "\n",
    "regression_predictions.plot(label='Regression', linewidth=2)\n",
    "\n",
    "# Histogram\n",
    "cars['mpg'].hist()\n",
    "xlabel('Miles per gallon')\n",
    "ylabel('Frequency')\n",
    "\n",
    "# Plot a normalized histogram\n",
    "# Calculate importances\n",
    "number_of_cars = len(cars['mpg'])\n",
    "importance_of_each_car = 1.0 / number_of_cars\n",
    "importance_list = [importance_of_each_car] * number_of_cars\n",
    "\n",
    "cars['mpg'].hist(bins=20, weights=importance_list) # Plot using these importances, using the \"weights\" argument of hist()\n",
    "xlabel('MPG')\n",
    "ylabel('Fraction of cars')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas 5 - GroupBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GroupBy\n",
    "mean_group_speed = cars.groupby(['cyl', 'manufacturer'])[['speed']].mean()\n",
    "\n",
    "# How do you access a hierarchical index? As a _tuple_\n",
    "mean_group_speed.loc[(3, 'Mazda')]\n",
    "\n",
    "# Group aggregations\n",
    "def speed_range(s):\n",
    "    \"\"\"Given a series of speeds (called s), get the range\"\"\"\n",
    "    return s.max() - s.min()\n",
    "\n",
    "cars.groupby(['cyl', 'manufacturer'])[['speed']].agg(speed_range)[:10] # Apply our aggregator using the agg() function\n",
    "\n",
    "# GroupBy with two agg functions\n",
    "ean_ratings = df.groupby(['movie_id', 'title'])['rating'].agg(['mean', 'count'])\n",
    "\n",
    "# Mask and sorting GroupBys \n",
    "at_least_1000 = mean_ratings[mean_ratings['count'] >= 1000] # mean_ratings is a groupby, movie_ids with at least 100 ratings\n",
    "at_least_1000.sort_values(by='mean', ascending=False)[:10]  # sort these by the mean\n",
    "\n",
    "# Who rates more? Men or women? Grouping and aggregating on same column\n",
    "df.groupby('gender')['gender'].count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas 6 - Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refer to time series notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas 7 - Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean of a series\n",
    "print 'The mean state population is', state_pop.mean()\n",
    "print 'The mean parent height is', parents.mean()\n",
    "\n",
    "# Standard Deviation of a series\n",
    "print 'The standard deviation of state populations is', state_pop.std()\n",
    "print 'The standard deviation of parent heights is', parents.std()\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "# We plot the histogram of parent heights \n",
    "parents.hist(bins=np.linspace(60, 75, 15), density=True)\n",
    "xlabel('Height of parent')\n",
    "\n",
    "# And a bell curve with exactly the same mean and standard deviation.\n",
    "x = np.linspace(60, 75, 100)\n",
    "plot(x, scipy.stats.norm.pdf(x, parents.mean(), parents.std()))\n",
    "\n",
    "# Values within 1 sd\n",
    "mean = parents.mean()\n",
    "sd = parents.std()\n",
    "mask_1_standard_dev = ((parents >= mean - sd) & (parents <= mean + sd))\n",
    "\n",
    "# Quantiles\n",
    "print '25-percentile =', state_pop.quantile(0.25)\n",
    "print 'Median = 50-percentile =', state_pop.quantile(0.5)\n",
    "print '75-percentile population =', state_pop.quantile(0.75)\n",
    "print '90-percentile =', state_pop.quantile(0.9)\n",
    "\n",
    "# Qcut - get 10 bins of equal size\n",
    "out = pd.qcut(state_pop, 10)\n",
    "out, bins = pd.qcut(state_pop, 10, retbins=True) # If we also want to get the bins formed by the quantiles\n",
    "\n",
    "# Describe provides a summary\n",
    "height_stats = heights.describe()\n",
    "census_pop_statistics = census_pop.groupby('REGION NAME').describe() #Groupby with describe\n",
    "\n",
    "# Correlation\n",
    "heights['parent'].corr(heights['child'])\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
